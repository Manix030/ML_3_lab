# -*- coding: utf-8 -*-
"""3-я Lab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L11g8areXAv3ksvWIw7XwstlqBVOQ2xJ
"""

# Лабораторная работа 3
# Козлов Максим Николаевич
# Вариант: 6 (ResNet152)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_curve
from sklearn.preprocessing import label_binarize

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import ResNet152
from tensorflow.keras.applications.resnet import preprocess_input, decode_predictions
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

import tensorflow_datasets as tfds

import requests
from io import BytesIO
from PIL import Image

import warnings
warnings.filterwarnings('ignore')

print("Все библиотеки успешно загружены")
print(f"TensorFlow версия: {tf.__version__}")

# 1. Загрузка предобученной сети ResNet152
print("Загружаем предобученную ResNet152 с весами ImageNet...")
model_resnet = ResNet152(weights='imagenet', include_top=True)

print("Модель ResNet152 загружена успешно!")
print(f"Входной размер изображения: {model_resnet.input_shape}")
print(f"Выходной размер (количество классов): {model_resnet.output_shape}")

# 2. Функция для классификации изображения по URL
def classify_image_from_url(url):
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()

        image = Image.open(BytesIO(response.content))
        image = image.convert('RGB')
        image = image.resize((224, 224))

        img_array = tf.keras.preprocessing.image.img_to_array(image)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = preprocess_input(img_array)

        predictions = model_resnet.predict(img_array, verbose=0)
        decoded = decode_predictions(predictions, top=3)[0]

        # Визуализация
        plt.figure(figsize=(12, 5))

        plt.subplot(1, 2, 1)
        plt.imshow(image)
        plt.axis('off')
        plt.title("Исходное изображение")

        plt.subplot(1, 2, 2)
        labels = [item[1] for item in decoded]
        probs = [item[2] for item in decoded]
        bars = plt.barh(labels, probs, color='skyblue')
        plt.xlabel('Вероятность')
        plt.title('Топ-3 предсказания')
        for bar, prob in zip(bars, probs):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                     f'{prob:.4f}', va='center', fontweight='bold')
        plt.xlim(0, 1)
        plt.tight_layout()
        plt.show()

        print("Топ-3 предсказания:")
        for i, (imid, label, prob) in enumerate(decoded):
            print(f"{i+1}. {label.replace('_', ' ')}: {prob:.4f}")

        return decoded

    except Exception as e:
        print(f"Ошибка при загрузке/обработке изображения: {e}")
        return None

# Список URL с изображениями (лошади, собаки, кошки — для теста)
image_urls = [
    "https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Horse_portrait_2.jpg/800px-Horse_portrait_2.jpg",  # лошадь
    "https://images.unsplash.com/photo-1543466835-00a7907e9de1?w=800",  # собака
    "https://images.unsplash.com/photo-1514888286974-6c03e2ca1dba?w=800"   # кошка
]

print("\nКлассификация изображений:")
for i, url in enumerate(image_urls):
    print(f"\nПопытка {i+1}:")
    result = classify_image_from_url(url)
    if result:
        print("✓ Успешно классифицировано")
        break
else:
    print("Все URL не сработали — проверьте интернет")

# 3. Функция загрузки и анализа датасетов
def load_and_analyze_dataset(dataset_name, max_train=None, max_test=None):
    print(f"\n=== Загрузка и анализ датасета: {dataset_name} ===")
    try:
        # Загрузка датасета
        if dataset_name == 'cats_vs_dogs':
            # cats_vs_dogs имеет только train split, делим вручную 80/20
            full_ds, info = tfds.load(dataset_name, split='train', with_info=True, as_supervised=True)
            total = info.splits['train'].num_examples
            train_size = int(0.8 * total)
            train_ds = full_ds.take(train_size)
            test_ds = full_ds.skip(train_size)
        else:
            # Для остальных (например horses_or_humans) есть готовые train/test
            (train_ds, test_ds), info = tfds.load(
                dataset_name, split=['train', 'test'], with_info=True, as_supervised=True
            )

        print(f"Количество классов: {info.features['label'].num_classes}")
        print(f"Имена классов: {info.features['label'].names}")

        # Ограничение размера (для ускорения на cats_vs_dogs)
        if max_train is not None:
            train_ds = train_ds.take(max_train)
        if max_test is not None:
            test_ds = test_ds.take(max_test)

        # Подсчёт примеров по классам
        def count_labels(ds):
            counts = [0] * info.features['label'].num_classes
            for _, label in ds:
                counts[label.numpy()] += 1
            return counts

        train_counts = count_labels(train_ds)
        test_counts = count_labels(test_ds)

        print(f"Train размер: {sum(train_counts)} примеров → {train_counts}")
        print(f"Test размер:  {sum(test_counts)} примеров → {test_counts}")

        # Гистограмма распределения классов
        plt.figure(figsize=(10, 4))
        x = np.arange(info.features['label'].num_classes)
        width = 0.35
        plt.bar(x - width/2, train_counts, width, label='Train', color='skyblue')
        plt.bar(x + width/2, test_counts,  width, label='Test',  color='orange')
        plt.xlabel('Класс')
        plt.ylabel('Количество примеров')
        plt.title(f'Распределение классов в {dataset_name}')
        plt.xticks(x, info.features['label'].names)
        plt.legend()
        plt.tight_layout()
        plt.show()

        return (train_ds, test_ds), info

    except Exception as e:
        print(f"Ошибка при загрузке {dataset_name}: {e}")
        return None, None

# Загружаем датасеты
print("Загрузка horses_or_humans...")
(horses_humans_train, horses_humans_test), hh_info = load_and_analyze_dataset('horses_or_humans')

print("\nЗагрузка cats_vs_dogs (маленькая версия для скорости)...")
(cats_dogs_train, cats_dogs_test), cd_info = load_and_analyze_dataset('cats_vs_dogs', max_train=1000, max_test=400)

print("\nДатасеты успешно загружены и проанализированы!")

# 4. Подготовка датасетов: ресайз, правильная нормализация для ResNet152 и батчинг
def prepare_dataset(dataset, batch_size=32, is_training=True):
    def preprocess(image, label):
        # Приводим к размеру 224×224, который требует ResNet
        image = tf.image.resize(image, (224, 224))
        # Специфическая предобработка ResNet152 (не просто /255!)
        image = preprocess_input(image)
        return image, label

    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)

    if is_training:
        dataset = dataset.shuffle(buffer_size=1000, seed=42)

    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

print("Подготовка horses_or_humans...")
hh_train_prepared = prepare_dataset(horses_humans_train, batch_size=32, is_training=True)
hh_test_prepared  = prepare_dataset(horses_humans_test,  batch_size=32, is_training=False)

print("Подготовка cats_vs_dogs (маленький датасет)...")
cd_train_prepared = prepare_dataset(cats_dogs_train, batch_size=32, is_training=True)
cd_test_prepared  = prepare_dataset(cats_dogs_test,  batch_size=32, is_training=False)

print("\nВсе датасеты успешно подготовлены для обучения!")
print(f"Пример батча horses_or_humans train: {next(iter(hh_train_prepared))[0].shape}")
print(f"Пример батча cats_vs_dogs train:     {next(iter(cd_train_prepared))[0].shape}")

# 5. Создание собственной свёрточной сети (без предобученных весов)
def create_custom_model(input_shape=(224, 224, 3), num_classes=2):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D(2, 2),

        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(256, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

print("Создаём и обучаем собственную CNN на датасете horses_or_humans...\n")

custom_model_hh = create_custom_model()

# Краткая информация о модели
custom_model_hh.summary()

# Обучение (5 эпох — достаточно для демонстрации)
history_hh = custom_model_hh.fit(
    hh_train_prepared,
    epochs=5,
    validation_data=hh_test_prepared,
    verbose=1
)

# Оценка на тесте
test_loss, hh_test_accuracy = custom_model_hh.evaluate(hh_test_prepared, verbose=0)
print(f"\nТочность собственной модели на horses_or_humans: {hh_test_accuracy:.4f}")

# 6. Transfer Learning: используем предобученную ResNet152 как feature extractor

# Загружаем базовую модель ResNet152 без верхних слоёв и с весами ImageNet
print("Загружаем базовую ResNet152 (без верхних слоёв)...")
base_resnet = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_resnet.trainable = False  # Замораживаем все слои базовой модели

print(f"Количество слоёв в базовой модели: {len(base_resnet.layers)}")
print("Базовая модель заморожена — будем обучать только новые верхние слои.\n")

# Функция создания модели для transfer learning
def create_transfer_model(base_model, num_classes=2):
    inputs = keras.Input(shape=(224, 224, 3))
    x = base_model(inputs, training=False)           # Пропускаем через замороженную базу
    x = GlobalAveragePooling2D()(x)                  # Усреднение по пространственным измерениям
    x = Dense(256, activation='relu')(x)             # Полносвязный слой
    x = Dropout(0.3)(x)                              # Регуляризация
    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs, outputs)

    model.compile(
        optimizer=Adam(learning_rate=0.0001),        # Маленький LR — важно при TL
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# === Дообучение на horses_or_humans ===
print("Создаём и обучаем модель Transfer Learning на horses_or_humans...\n")
tl_model_hh = create_transfer_model(base_resnet)

# Краткая информация
tl_model_hh.summary(line_length=100)

# Обучение (5 эпох)
history_tl_hh = tl_model_hh.fit(
    hh_train_prepared,
    epochs=5,
    validation_data=hh_test_prepared,
    verbose=1
)

# Оценка
_, tl_hh_test_accuracy = tl_model_hh.evaluate(hh_test_prepared, verbose=0)
print(f"\nТочность Transfer Learning на horses_or_humans: {tl_hh_test_accuracy:.4f}")

# === Дообучение на cats_vs_dogs (маленький датасет) ===
print("\n\nСоздаём и обучаем модель Transfer Learning на cats_vs_dogs...\n")
tl_model_cd = create_transfer_model(base_resnet)

history_tl_cd = tl_model_cd.fit(
    cd_train_prepared,
    epochs=5,
    validation_data=cd_test_prepared,
    verbose=1
)

# Оценка
_, tl_cd_test_accuracy = tl_model_cd.evaluate(cd_test_prepared, verbose=0)
print(f"\nТочность Transfer Learning на cats_vs_dogs: {tl_cd_test_accuracy:.4f}")

print("\nДообучение завершено! Обычно точность TL > 0.95 даже на маленьком датасете.")

# 7. ИСПРАВЛЕННАЯ функция evaluate_model — без ошибки и со всеми графиками
def evaluate_model(model, test_dataset, class_names, dataset_name):
    print(f"\n=== Полная оценка модели на датасете: {dataset_name} ===")

    y_true = []
    y_pred = []
    y_pred_proba = []

    # КЛЮЧЕВОЙ ФИКС: unbatch + по одному примеру
    print("Сбор предсказаний (по одному примеру для точности)...")
    for image, label in test_dataset.unbatch():
        image = tf.expand_dims(image, axis=0)
        pred = model(image, training=False)
        y_pred_proba.append(pred.numpy()[0])
        y_pred.append(np.argmax(pred.numpy(), axis=1)[0])
        y_true.append(label.numpy())

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    y_pred_proba = np.array(y_pred_proba)

    print(f"Обработано примеров: {len(y_true)}")

    # Остальные графики (оставь как есть — они у тебя отличные)
    plt.figure(figsize=(15, 10))

    # 1. Confusion Matrix
    plt.subplot(2, 3, 1)
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix\n{dataset_name}')
    plt.ylabel('Истинные метки')
    plt.xlabel('Предсказанные метки')

    # 2. Метрики по классам
    plt.subplot(2, 3, 2)
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    metrics_df = pd.DataFrame(report).transpose()
    metrics_df[['precision', 'recall', 'f1-score']].iloc[:-3].plot(kind='bar', ax=plt.gca())
    plt.title('Метрики по классам')
    plt.xticks(rotation=45)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # 3. PR-кривая по классам
    plt.subplot(2, 3, 3)
    if len(class_names) == 2:
        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba[:, 1])
        plt.plot(recall, precision, lw=2, label='PR Curve')
    else:
        y_true_bin = label_binarize(y_true, classes=range(len(class_names)))
        for i in range(len(class_names)):
            precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_proba[:, i])
            plt.plot(recall, precision, lw=2, label=f'{class_names[i]}')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('PR-кривые по классам')
    plt.legend()
    plt.grid(True)

    # 4. PR-кривые с микроусреднением
    plt.subplot(2, 3, 4)
    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))
    precision_micro, recall_micro, _ = precision_recall_curve(y_true_bin.ravel(), y_pred_proba.ravel())
    plt.plot(recall_micro, precision_micro, lw=2, color='red', label='Micro-average')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('PR-кривaя (Micro-average)')
    plt.legend()
    plt.grid(True)

    # 5. Сводные метрики (Accuracy, Precision, Recall, F1)
    plt.subplot(2, 3, 5)
    accuracy = accuracy_score(y_true, y_pred)
    precision_w = report['weighted avg']['precision']
    recall_w = report['weighted avg']['recall']
    f1_w = report['weighted avg']['f1-score']

    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    values = [accuracy, precision_w, recall_w, f1_w]
    bars = plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])
    plt.title('Сводные метрики качества')
    plt.ylim(0, 1.1)
    for bar, val in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                 f'{val:.3f}', ha='center', va='bottom', fontweight='bold')
    plt.xticks(rotation=45)

    # 6. Распределение вероятностей
    plt.subplot(2, 3, 6)
    if len(class_names) == 2:
        y_scores = y_pred_proba[:, 1]
        correct = (y_pred == y_true)
        incorrect = (y_pred != y_true)
        plt.hist(y_scores[correct], bins=20, alpha=0.7, label='Правильные', color='green')
        plt.hist(y_scores[incorrect], bins=20, alpha=0.7, label='Неправильные', color='red')
        plt.xlabel('Вероятность положительного класса')
        plt.ylabel('Количество')
        plt.title('Распределение вероятностей')
        plt.legend()
    else:
        max_probs = np.max(y_pred_proba, axis=1)
        plt.hist(max_probs, bins=20, alpha=0.7, color='purple')
        plt.xlabel('Максимальная вероятность')
        plt.title('Уверенность модели')

    evaluate_model(tl_model_hh, hh_test_prepared, hh_info.features['label'].names, "horses_or_humans")
    evaluate_model(tl_model_cd, cd_test_prepared, cd_info.features['label'].names, "cats_vs_dogs")

    plt.tight_layout()
    plt.show()

# 8. Итоговая сводка результатов

print(f"{'Датасет':<25} {'Собственная CNN':<20} {'ResNet152 (TL)':<20}")
print("-"*65)
print(f"{'horses_or_humans':<25} {hh_test_accuracy:<18.4f}   {tl_hh_test_accuracy:.4f}")
print(f"{'cats_vs_dogs':<25} {'—':<18}   {tl_cd_test_accuracy:.4f}")
print("="*60)

# Функция для визуализации истории обучения
def plot_training_history(history, title):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy', marker='o')
    plt.title(f'{title} — Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss', marker='o')
    plt.plot(history.history['val_loss'], label='Val Loss', marker='o')
    plt.title(f'{title} — Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Графики для Transfer Learning моделей
print("\nГрафики обучения Transfer Learning моделей:\n")

plot_training_history(history_tl_hh, "ResNet152 — horses_or_humans")
plot_training_history(history_tl_cd, "ResNet152 — cats_vs_dogs")